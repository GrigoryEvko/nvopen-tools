// Function: sub_14A3F50
// Address: 0x14a3f50
//
__int64 __fastcall sub_14A3F50(__m128i *a1, __m128i *a2)
{
  __m128i v2; // xmm1
  __int64 v3; // rdx
  __int64 v4; // rax
  __m128i v5; // xmm0
  __int64 v6; // rax
  __int64 v7; // rax

  a1->m128i_i64[1] = 0;
  v2 = _mm_loadu_si128(a1 + 10);
  a1[1].m128i_i64[0] = (__int64)&unk_4F9D3C0;
  v3 = a1[11].m128i_i64[1];
  a1[5].m128i_i64[0] = (__int64)a1[4].m128i_i64;
  a1[5].m128i_i64[1] = (__int64)a1[4].m128i_i64;
  a1[8].m128i_i64[0] = (__int64)a1[7].m128i_i64;
  a1[8].m128i_i64[1] = (__int64)a1[7].m128i_i64;
  a1[11].m128i_i64[0] = 0;
  a1[1].m128i_i32[2] = 5;
  a1[2].m128i_i64[0] = 0;
  a1[2].m128i_i64[1] = 0;
  a1[3].m128i_i64[0] = 0;
  a1[4].m128i_i32[0] = 0;
  a1[4].m128i_i64[1] = 0;
  a1[6].m128i_i64[0] = 0;
  a1[7].m128i_i32[0] = 0;
  a1[7].m128i_i64[1] = 0;
  a1[9].m128i_i64[0] = 0;
  a1[9].m128i_i8[8] = 0;
  a1->m128i_i64[0] = (__int64)&unk_49ECA68;
  v4 = a2[1].m128i_i64[0];
  v5 = _mm_loadu_si128(a2);
  a2[1].m128i_i64[0] = 0;
  a1[11].m128i_i64[0] = v4;
  v6 = a2[1].m128i_i64[1];
  a1[10] = v5;
  a2[1].m128i_i64[1] = v3;
  *a2 = v2;
  a1[11].m128i_i64[1] = v6;
  a1[12].m128i_i8[8] = 0;
  v7 = sub_163A1D0(a1, a2);
  return sub_14A3D70(v7);
}
