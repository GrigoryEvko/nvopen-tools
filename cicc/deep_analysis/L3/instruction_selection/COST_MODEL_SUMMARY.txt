================================================================================
INSTRUCTION SELECTION COST MODEL - COMPLETE EXTRACTION
Agent: L3-02 Cost Model Coefficients Extraction
Date: 2025-11-16
Confidence: HIGH
================================================================================

EXECUTIVE SUMMARY
-----------------
The instruction selection cost model uses a floating-point-like representation
to compare and optimize instruction sequences. Costs are computed as weighted
sums of multiple metrics (latency, throughput, register pressure) and stored
as (mantissa, exponent) pairs for precision and dynamic range.

COST REPRESENTATION (Critical Detail)
-------------------------------------
Format: FLOATING_POINT_LIKE_PAIR
  Mantissa: 64-bit unsigned integer (0 to 2^64-1)
  Exponent: 16-bit signed integer (0 to 0x3FFF = 16383)
  Bias: 16382

This allows costs ranging from 0 to 2^16382 * 2^64 with ~64-bit mantissa
precision. The exponent provides exponential dynamic range, exponent provides
exponential dynamic range for costs that differ by orders of magnitude.

COST FORMULA
------------
High-Level:
  final_cost = WEIGHTED_SUM(metric1, metric2, metric3, ...)

Computation Pattern:
  1. Extract individual metrics from instruction cost table (latency, throughput)
  2. Scale each metric by weight coefficient (1, 3, 64, 100)
  3. Accumulate weighted costs using exponent-aligned addition
  4. Normalize final result to handle overflow/underflow
  5. Compare with alternative instruction costs

Observed Weight Values:
  - Weight 100: Main aggregation weight (most critical)
  - Weight 1: Direct metric use (identity)
  - Weight 3: Inverse weight (1/3 approximation)
  - Weight 64: Inverse weight (1/64 approximation)

KEY FUNCTIONS (By Responsibility)
----------------------------------

1. COST CALCULATION & NORMALIZATION
   sub_FDE760 (0xfde760) - 531 bytes
   - Entry point for cost normalization
   - Handles overflow by setting mantissa=-1, exponent=0x3FFF (infinity)
   - Calls sub_F04200 for fixed-point conversion
   - Calls sub_D78C90 for exponent adjustment

2. COST COMPARISON
   sub_D788E0 (0xd788e0) - 681 bytes
   - Compares two costs with different exponents
   - Returns: -1 (cost1 > cost2), 0 (equal), +1 (cost2 > cost1)
   - Uses sub_D788C0 for exponent comparison
   - Uses sub_F042F0 for mantissa comparison if exponents are close

3. EXPONENT ADJUSTMENT
   sub_D78C90 (0xd78c90) - 82 bytes
   - Adjusts cost exponent and mantissa for scaling
   - Negative adjustment: shift mantissa right, decrement exponent
   - Positive adjustment: shift mantissa left, increment exponent
   - Clamps exponent to valid range [0, 0x3FFF]

4. COST ADDITION WITH ALIGNMENT
   sub_FDCA70 (0xfdca70) - 66 bytes
   - Adds two costs by aligning exponents and summing mantissas
   - If exponent difference <= 127:
     * Shift smaller mantissa right by difference
     * Add aligned mantissas
     * Normalize result exponents
   - Else: Return larger exponent value (smaller cost becomes negligible)

5. COST WEIGHTING (MULTIPLICATION)
   sub_2F9DA20 (0x2f9da20) - 45 bytes
   - Multiplies metric by weight and adds to accumulated cost
   - Formula: result = a1 * cost_mantissa
            result_exponent = a2 + cost_exponent
   - Uses sub_F04140 for large multiplications

6. COST SUBTRACTION
   sub_2F9CA30 (0x2f9ca30) - 34 bytes
   - Subtracts second cost from first
   - Used for cost benefit analysis in optimization decisions

COST DATA STRUCTURE
-------------------
Pattern Entry Size: 40 bytes (indexed hash table)

Offset  Size  Type    Description
------  ----  ----    -----------
0       8     qword   Pattern identifier
8       8     qword   Metric 1 mantissa (latency/critical path)
16      2     word    Metric 1 exponent
18      6     -       Alignment padding
24      8     qword   Metric 2 mantissa (throughput/resources)
32      2     word    Metric 2 exponent
34      6     -       Alignment padding

Hash Table Details:
  - Hash function uses: (id ^ (id >> 9) ^ (id >> 4)) & (mask)
  - Linear probing for collision resolution
  - Stored in v322 in pattern matcher (sub_2F9DAC0)
  - Accessed as: v322 + 40LL * hash_index

PATTERN MATCHER INTEGRATION
-----------------------------
Main function: sub_2F9DAC0 (0x2f9dac0) - 50 KB, 1862 lines

Typical Cost Evaluation Flow:
  1. For each instruction pattern:
     - Hash pattern ID into table
     - Extract cost metrics (latency, throughput)
     - Keep minimum costs seen so far

  2. Compute combined cost:
     - Extract raw metrics from patterns
     - Apply weights (sub_2F9DA20)
     - Add components (sub_FDCA70)
     - Normalize result (sub_FDE760)

  3. Compare alternatives:
     - Use sub_D788E0 to compare costs
     - Select instruction sequence with minimum cost

  4. Key cost aggregation (line 1125):
     - Applies final weight of 100
     - Normalizes with sub_FDE760
     - This is the main decision point

COST METRICS (Inferred from Context)
------------------------------------
Two primary metrics stored per instruction pattern:

Metric 1 (Offset 8-16): LATENCY COST
  - Measures impact on critical path
  - Critical for loop-carried dependencies
  - Directly affects program execution time

Metric 2 (Offset 24-32): THROUGHPUT/RESOURCE COST
  - Measures resource utilization (registers, functional units)
  - Affects parallelism and IPC
  - May include register pressure component

Possible additional metrics (computed dynamically):
  - Register pressure cost
  - Memory latency cost
  - Control flow cost

SM-SPECIFIC DIFFERENCES
------------------------
Not directly visible in instruction selection code.
Latency values are baked into cost tables at compile time.

Likely architectures supported:
  - SM 7.0 (Volta)
  - SM 7.5 (Turing)
  - SM 8.0 (Ampere)
  - SM 8.6 (Ampere)
  - SM 9.0 (Hopper)

Cost tables located in:
  - Global data section (read from binary)
  - Indexed by instruction opcode
  - Different table for each SM architecture

ALGORITHM CORRECTNESS NOTES
----------------------------
1. Exponent Range: 0-0x3FFF ensures no negative costs
   - 0x3FFF represents "infinity" cost (infeasible instructions)
   - Mantissa of -1 indicates uncomputable cost

2. Precision: 64-bit mantissa provides ~19 decimal digits precision
   - Sufficient for distinguishing between alternatives
   - Exponent allows cost ratios up to 2^16382 between alternatives

3. Overflow Handling:
   - If mantissa overflows during multiplication, clamped to -1
   - If exponent exceeds 0x3FFF, clamped to 0x3FFF
   - Represents "very expensive" or "not feasible" instruction

4. Underflow Handling:
   - If mantissa underflows (becomes 0), cost becomes 0
   - If exponent < 0, adjusted to 0
   - Represents "very cheap" instruction

5. Addition Precision:
   - If exponent difference > 127 bits, smaller cost ignored
   - This is intentional - difference becomes negligible at that scale
   - Prevents precision loss in large sums

WEIGHT INFERENCE
----------------
Observed weights in code (high confidence):
  - Weight 100: Line 1125 in pattern matcher (main decision point)
  - Weight 3: Lines 1034, 1056 (secondary calculations)
  - Weight 64: Line 1493 (fine-grained adjustments)
  - Weight 1: Lines 785-810 (direct metric usage)

Likely purposes:
  - 100: Amplifies main cost metric for decision sensitivity
  - 3: Reduces secondary metric (1/3 scaling)
  - 64: Fine adjustment (1/64 scaling)
  - 1: Identity (no scaling)

These weights likely come from:
  - Compiler tuning/empirical optimization
  - NVIDIA-provided cost model parameters
  - Configuration not visible in decompiled code

FILES ANALYZED
--------------
1. sub_FDE760_0xfde760.c      - Cost normalization
2. sub_D788E0_0xd788e0.c      - Cost comparison
3. sub_F04200_0xf04200.c      - Fixed-point conversion
4. sub_D78C90_0xd78c90.c      - Exponent adjustment
5. sub_FDCA70_0xfdca70.c      - Cost addition
6. sub_2F9DA20_0x2f9da20.c    - Cost weighting
7. sub_2F9DAC0_0x2f9dac0.c    - Pattern matcher (main consumer)

Total Analysis: 1862 lines of decompiled code
Confidence Level: HIGH (complete function reconstruction)

UNRESOLVED QUESTIONS
--------------------
1. Exact weight values for each metric component
   - Encoded in binary, not visible in decompiled code
   - Likely in configuration or tuning data section

2. Complete cost formula breakdown
   - Multiple unknown coefficients
   - Sub-metric calculations hidden in other functions

3. SM-specific latency tables
   - Not included in analyzed functions
   - Likely separate data structure indexed by SM version

4. Cost units interpretation
   - Are costs in cycles? Abstract units? Normalized values?
   - Relative comparison is what matters for optimization

5. Register pressure component
   - Mentioned in earlier search results
   - Not directly visible in main cost calculation

RECOMMENDATIONS FOR FURTHER ANALYSIS
-------------------------------------
1. Locate and analyze the global cost tables in the binary data
   - Search for SM-specific marker strings
   - Extract latency values for each instruction opcode
   - Compare across different SM architectures

2. Find the weight configuration/tuning data
   - Search for where weights 100, 3, 64 are loaded
   - May be in config section or computed at initialization

3. Identify missing cost components
   - Register pressure calculation
   - Memory latency effects
   - Control flow penalties

4. Cross-reference with NVIDIA documentation
   - CUDA C++ Programming Guide: instruction latencies
   - cuDNN/TensorRT: cost model documentation
   - NVIDIA Nsight documentation

5. Validate against actual measurements
   - Compare predicted costs with measured instruction latencies
   - Tune weights if predictions don't match reality
   - Test across different SM architectures

================================================================================
END OF SUMMARY
================================================================================
