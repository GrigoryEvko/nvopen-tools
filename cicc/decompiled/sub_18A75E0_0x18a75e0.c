// Function: sub_18A75E0
// Address: 0x18a75e0
//
void __fastcall sub_18A75E0(__m128i *a1, _BYTE *a2, __int64 a3)
{
  __m128i v3; // xmm0
  __m128i v4; // xmm1
  __m128i v5; // xmm2
  __int64 v6; // rax
  __m128i v7; // xmm0
  __int64 v8; // rax
  __int8 *v9; // rax
  void (__fastcall *v10)(__m128i *, __m128i *, __int64); // rax
  __int64 v11; // rax
  __m128i v12; // [rsp+0h] [rbp-50h] BYREF
  void (__fastcall *v13)(__m128i *, __m128i *, __int64); // [rsp+10h] [rbp-40h]
  __int64 v14; // [rsp+18h] [rbp-38h]
  __m128i v15; // [rsp+20h] [rbp-30h] BYREF
  void (__fastcall *v16)(__m128i *, __m128i *, __int64); // [rsp+30h] [rbp-20h]
  __int64 v17; // [rsp+38h] [rbp-18h]

  a1[1].m128i_i64[0] = (__int64)&unk_4FAD21C;
  a1[5].m128i_i64[0] = (__int64)a1[4].m128i_i64;
  a1[5].m128i_i64[1] = (__int64)a1[4].m128i_i64;
  a1[8].m128i_i64[0] = (__int64)a1[7].m128i_i64;
  a1[8].m128i_i64[1] = (__int64)a1[7].m128i_i64;
  a1->m128i_i64[0] = (__int64)off_49F1FE8;
  a1->m128i_i64[1] = 0;
  a1[1].m128i_i32[2] = 5;
  a1[2].m128i_i64[0] = 0;
  a1[2].m128i_i64[1] = 0;
  a1[3].m128i_i64[0] = 0;
  a1[4].m128i_i32[0] = 0;
  a1[4].m128i_i64[1] = 0;
  a1[6].m128i_i64[0] = 0;
  a1[7].m128i_i32[0] = 0;
  a1[7].m128i_i64[1] = 0;
  a1[9].m128i_i64[0] = 0;
  a1[9].m128i_i8[8] = 0;
  v15.m128i_i64[0] = (__int64)a1;
  v12.m128i_i64[0] = (__int64)a1;
  a1[10].m128i_i64[0] = 0;
  a1[10].m128i_i64[1] = 0;
  a1[11].m128i_i64[0] = 0;
  a1[11].m128i_i32[2] = 0;
  a1[12].m128i_i64[0] = 0;
  a1[12].m128i_i64[1] = 0;
  a1[13].m128i_i64[0] = 0;
  a1[13].m128i_i32[2] = 0;
  a1[14].m128i_i64[0] = 0;
  a1[14].m128i_i64[1] = (__int64)&a1[16].m128i_i64[1];
  v3 = _mm_loadu_si128(&v12);
  a1[15].m128i_i64[0] = (__int64)&a1[16].m128i_i64[1];
  v4 = _mm_loadu_si128(a1 + 74);
  a1[32].m128i_i64[1] = (__int64)&a1[33].m128i_i64[1];
  v5 = _mm_loadu_si128(a1 + 76);
  a1[33].m128i_i64[0] = 0x2000000000LL;
  a1[67].m128i_i64[0] = (__int64)a1[66].m128i_i64;
  a1[67].m128i_i64[1] = (__int64)a1[66].m128i_i64;
  a1[71].m128i_i64[1] = 0x1000000000LL;
  a1[75].m128i_i64[0] = (__int64)sub_18A35B0;
  v6 = a1[75].m128i_i64[1];
  a1[74] = v3;
  v7 = _mm_loadu_si128(&v15);
  v14 = v6;
  a1[75].m128i_i64[1] = (__int64)sub_18A3570;
  a1[15].m128i_i64[1] = 32;
  a1[16].m128i_i32[0] = 0;
  a1[66].m128i_i32[0] = 0;
  a1[66].m128i_i64[1] = 0;
  a1[68].m128i_i64[0] = 0;
  a1[68].m128i_i64[1] = 0;
  a1[69].m128i_i64[0] = 0;
  a1[69].m128i_i64[1] = 0;
  a1[70].m128i_i32[0] = 0;
  a1[70].m128i_i64[1] = 0;
  a1[71].m128i_i64[0] = 0;
  a1[72].m128i_i64[1] = 0;
  a1[73].m128i_i64[0] = 0;
  a1[73].m128i_i64[1] = 0;
  v13 = 0;
  v12 = v4;
  v15 = v5;
  a1[76] = v7;
  a1[77].m128i_i64[0] = (__int64)sub_18A3580;
  v8 = a1[77].m128i_i64[1];
  v16 = 0;
  v17 = v8;
  a1[77].m128i_i64[1] = (__int64)sub_18A3560;
  v9 = &a1[86].m128i_i8[8];
  a1[78].m128i_i64[0] = 0;
  a1[78].m128i_i64[1] = 0;
  a1[79].m128i_i64[0] = 0;
  a1[79].m128i_i32[2] = 0;
  a1[80].m128i_i64[0] = 0;
  a1[80].m128i_i64[1] = 0;
  a1[81].m128i_i64[0] = 0;
  a1[81].m128i_i32[2] = 0;
  a1[82].m128i_i64[0] = 0;
  a1[82].m128i_i64[1] = 0;
  a1[83].m128i_i64[0] = 0;
  a1[83].m128i_i32[2] = 0;
  a1[84].m128i_i64[0] = 0;
  a1[84].m128i_i64[1] = 0;
  a1[85].m128i_i64[0] = 0;
  if ( a2 )
  {
    a1[85].m128i_i64[1] = (__int64)v9;
    sub_18A3750(&a1[85].m128i_i64[1], a2, (__int64)&a2[a3]);
    v10 = v13;
    a1[88].m128i_i64[0] = 0;
    a1[87].m128i_i16[4] = 0;
    a1[88].m128i_i64[1] = 0;
    a1[89].m128i_i64[0] = 0;
    if ( v10 )
      v10(&v12, &v12, 3);
  }
  else
  {
    a1[85].m128i_i64[1] = (__int64)v9;
    a1[86].m128i_i64[0] = 0;
    a1[86].m128i_i8[8] = 0;
    a1[87].m128i_i16[4] = 0;
    a1[88].m128i_i64[0] = 0;
    a1[88].m128i_i64[1] = 0;
    a1[89].m128i_i64[0] = 0;
  }
  if ( v16 )
    v16(&v15, &v15, 3);
  a1[89].m128i_i64[1] = 0;
  a1[90].m128i_i64[0] = 0;
  v11 = sub_163A1D0();
  sub_18A74F0(v11);
}
